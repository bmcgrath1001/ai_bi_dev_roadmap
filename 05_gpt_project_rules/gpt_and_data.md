# üß† Teaching ChatGPT Your Data: Best Practices

This guide outlines how to safely and effectively give ChatGPT context about your data lake, table schemas, and pipeline logic ‚Äî without sharing credentials or exposing sensitive data.

The goal is to treat ChatGPT like a secure, high-context **AI pair programmer** who can reason with structure, metadata, and business meaning.

---

## ‚úÖ Phase 1: Teach the Shape of the Data

### A. Share Schema Extracts

Use SQL to generate table structure:

```sql
SHOW COLUMNS FROM snap_analytics.snapdata.customer_account;
```

Or via information_schema:

```sql
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_schema = 'snapdata' 
  AND table_name = 'customer_account';
```

Paste the result into ChatGPT along with your goal:

> ‚ÄúHere‚Äôs the schema for `customer_account`. Help me write cleaning logic or build a dbt model for it.‚Äù

üìÅ You can also version this in your repo as:

00_foundations/schemas/customer_account.md

---

### üß† B. Add Business Meaning

Include semantic info ChatGPT can reason with:

> ‚ÄúThe `fraud_flag` in `customer_application` marks apps auto-flagged by rules.  
> Final verdicts come from `fraud_investigation_outcomes`.‚Äù

This helps with:
- Feature engineering  
- Cohort tracking  
- Dashboard metrics alignment

---

## üìò Phase 2: Build a Data Dictionary

Already working in Excel or Markdown? Upload it directly.

ChatGPT can help you:
- Autogenerate field descriptions  
- Flag inconsistent naming or logic  
- Suggest validation or cleaning rules  

Keep it lightweight or modular:

00_foundations/data_dictionary/fraud_tables.xlsx

---

## üîó Phase 3: Simulate Workflow Access

ChatGPT can‚Äôt directly query S3 or Trino ‚Äî but you can simulate access by pasting context:

| **Task**              | **How to Give Context**                                             |
|-----------------------|----------------------------------------------------------------------|
| Query optimization    | Paste SQL + platform (Trino, Postgres, etc.)                         |
| Pipeline review       | Paste DAG logic or Airflow `.py` task                                |
| Debugging help        | Paste error + code snippet                                           |
| Performance tuning    | Mention volume, filter columns, and partition strategy               |
| ETL logic generation  | Describe the source ‚Üí staging ‚Üí curated path                         |
